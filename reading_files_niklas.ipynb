{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a166ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imageio as iio\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c345608",
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    \"ASL_letter_A\",\n",
    "    \"ASL_letter_B\",\n",
    "    \"ASL_letter_C\",\n",
    "    \"ASL_letter_L\",\n",
    "    \"ASL_letter_R\",\n",
    "    \"ASL_letter_U\",\n",
    "]\n",
    "\n",
    "joints = [\n",
    "    \"root\",\n",
    "    \"thumb_1\",\n",
    "    \"thumb_2\",\n",
    "    \"thumb_3\",\n",
    "    \"index_1\",\n",
    "    \"index_2\",\n",
    "    \"index_3\",\n",
    "    \"index_4\",\n",
    "    \"middle_1\",\n",
    "    \"middle_2\",\n",
    "    \"middle_3\",\n",
    "    \"middle_4\",\n",
    "    \"ring_1\",\n",
    "    \"ring_2\",\n",
    "    \"ring_3\",\n",
    "    \"ring_4\",\n",
    "    \"pinky_1\",\n",
    "    \"pinky_2\",\n",
    "    \"pinky_3\",\n",
    "    \"pinky_4\"\n",
    "]\n",
    "\n",
    "train_imp = pd.read_csv(\"1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c394d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frame_data': Array([[[139, 121, 100],\n",
      "        [139, 121, 100],\n",
      "        [139, 121, 100],\n",
      "        ...,\n",
      "        [198, 197, 188],\n",
      "        [197, 196, 187],\n",
      "        [198, 197, 188]],\n",
      "\n",
      "       [[139, 121, 100],\n",
      "        [139, 121, 100],\n",
      "        [139, 121, 100],\n",
      "        ...,\n",
      "        [198, 197, 188],\n",
      "        [198, 197, 188],\n",
      "        [198, 197, 188]],\n",
      "\n",
      "       [[139, 121, 100],\n",
      "        [139, 121, 100],\n",
      "        [139, 121, 100],\n",
      "        ...,\n",
      "        [198, 197, 188],\n",
      "        [198, 197, 188],\n",
      "        [198, 197, 188]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[173, 168, 167],\n",
      "        [173, 168, 167],\n",
      "        [173, 168, 167],\n",
      "        ...,\n",
      "        [ 30,  29,  32],\n",
      "        [ 27,  26,  29],\n",
      "        [ 27,  26,  29]],\n",
      "\n",
      "       [[173, 168, 167],\n",
      "        [173, 168, 167],\n",
      "        [173, 168, 167],\n",
      "        ...,\n",
      "        [ 31,  30,  33],\n",
      "        [ 29,  28,  31],\n",
      "        [ 29,  28,  31]],\n",
      "\n",
      "       [[173, 168, 167],\n",
      "        [173, 168, 167],\n",
      "        [173, 168, 167],\n",
      "        ...,\n",
      "        [ 31,  30,  33],\n",
      "        [ 29,  28,  31],\n",
      "        [ 29,  28,  31]]], dtype=uint8), 'condition': 'ASL_letter_B', 'frame_number': 82}\n",
      "(0, ID                     0\n",
      "gesture     ASL_letter_A\n",
      "frame                  0\n",
      "joint      hand_position\n",
      "x                    0.0\n",
      "y                    0.0\n",
      "Name: 0, dtype: object)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cf/pw1h2ybx4y51r2y9kbm86g040000gn/T/ipykernel_61064/3652548901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"hejsan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cf/pw1h2ybx4y51r2y9kbm86g040000gn/T/ipykernel_61064/3652548901.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gesture\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"condition\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"frame_number\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"joint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mjoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     key = {\n\u001b[1;32m     35\u001b[0m                         \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def generate_random_train_set():\n",
    "    # currently only using the files starting with a \"1\" \n",
    "    train_set = []\n",
    "    for condition in gestures:\n",
    "            with iio.imopen(f\"1{condition}_anonymous.mp4\", \"r\", format=\"ffmpeg\") as video_in:\n",
    "                frames = video_in.read() # The frames are on type \"list\"\n",
    "                for i in range(len(frames)):\n",
    "                    # i will be the frame number - corresponding to column c in the csv\n",
    "                    train_set.append({\n",
    "                        \"frame_data\": frames[i],\n",
    "                        \"condition\": condition,\n",
    "                        \"frame_number\": i\n",
    "                    })\n",
    "                    \n",
    "                    # train set on form\n",
    "                    # \"frame_data\" = the data of the frame\n",
    "                    # \"condition\" = the actual letter being signed - column b\n",
    "                    # \"frame_number\" = the frame number - column c\n",
    "    \n",
    "    rand_train_set = sorted(train_set, key=lambda k: random.random())\n",
    "    print(rand_train_set[1400])\n",
    "    return rand_train_set\n",
    "\n",
    "def train():\n",
    "    train_csv = train_imp\n",
    "    train_set = generate_random_train_set() # generating a new random set everytime means that \n",
    "                                            # even though the frames are the same, the order in which\n",
    "                                            # they appear will be different. Nice?\n",
    "    \n",
    "    for frame in train_set:\n",
    "        cnn_landmarks = train_landmarks(frame[\"frame_data\"])\n",
    "        for joint in joints:\n",
    "            # iterate over the .csv-file - loss function!\n",
    "                # if entry[\"gesture\"] == frame[\"condition\"] and entry[\"frame\"] == frame[\"frame_number\"] and entry[\"joint\"] == joint:\n",
    "                   # key = {\n",
    "                    #     \"x\": entry[\"x\"],\n",
    "                    #     \"y\": entry[\"y\"],\n",
    "                    #     \"joint\": joint\n",
    "                    # }\n",
    "                    # Above is a way to create a key for each frame\n",
    "                    # the key will contain the correct info that the frame represents\n",
    "                    # that is gotten from the .csv-file.\n",
    "                    #\n",
    "                    # This information will be used to validate the model in the loss function\n",
    "            \n",
    "            eval_landmarks(cnn_landmarks, joint_data)\n",
    "    \n",
    "def train_landmarks(frame_data):\n",
    "    # some function guessing the landmarks\n",
    "    # do something with the frame_data\n",
    "    # here is where the actual U-net will be placed!!\n",
    "    guessed_landmarks = []\n",
    "    return guessed_landmarks\n",
    "\n",
    "def eval_landmarks(cnn, key):\n",
    "    # this is the loss function!\n",
    "    return \"hejsan\"\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a56975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 11:15:49.573894: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "#Defining the Convolutional Neural Network\n",
    "cnn_model = Sequential()\n",
    "\n",
    "cnn_model.add(Conv2D(32, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "cnn_model.add(Conv2D(64, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "cnn_model.add(Conv2D(128, (3, 3), input_shape = (28,28,1), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.add(Dense(units = 512, activation = 'relu'))\n",
    "cnn_model.add(Dropout(0.25))\n",
    "cnn_model.add(Dense(units = 25, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd725765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
